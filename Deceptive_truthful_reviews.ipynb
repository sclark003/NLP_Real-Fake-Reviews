{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import csv                               # csv reader\n",
    "import re\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import enchant\n",
    "import math\n",
    "\n",
    "# PRE-PROCESSING\n",
    "from nltk import bigrams\n",
    "from nltk.classify import SklearnClassifier\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.metrics import edit_distance\n",
    "\n",
    "# FEATURES\n",
    "import spacy\n",
    "from collections import Counter, OrderedDict\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# CLASSIFICATION\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Split Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and append to rawData\n",
    "def loadData(file, Text=None):\n",
    "    rawData = []\n",
    "    with open(file, encoding = \"utf8\") as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        for line in reader:\n",
    "            rawData.append(parseReview(line))\n",
    "        rawData = rawData[1:]  #remove header row\n",
    "        return rawData\n",
    "\n",
    "# convert line into text/label pair\n",
    "def parseReview(line):\n",
    "    Label = line[0]\n",
    "    Polarity = line[2]\n",
    "    Text = line[4]\n",
    "    return (Text,Polarity,Label)\n",
    "\n",
    "\n",
    "# A method to split the data between trainData and testData\n",
    "def splitData(data,percentage):\n",
    "    splitSample = len(data)*percentage\n",
    "    i = 0\n",
    "    for Text,Polarity,Label in data:\n",
    "        if i< splitSample:\n",
    "            trainData.append((Text,Polarity,Label))\n",
    "            #trainData.append((preProcess(Text),Polarity,Label))\n",
    "            #trainData.append(((toFeatureVector((preProcess(Text)),Polarity)),Label))\n",
    "        if i>= splitSample:\n",
    "            testData.append((Text,Polarity,Label))\n",
    "            #testData.append((preProcess(Text),Polarity,Label))\n",
    "            #testData.append(((toFeatureVector((preProcess(Text)),Polarity)),Label))\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT PREPROCESSING\n",
    "\n",
    "# Input: a string of one review\n",
    "def preProcess(text):\n",
    "    #This function takes in the text part of each review in order to turn it into tokens\n",
    "    #For the feature dictionary we just want to remove any punctuation and just take the words/numbers as features\n",
    "    #Here, the text is 'cleaned' by removing line breaks and punctuation, and then splitting the resulting string of words\n",
    "    #At each whitespace, to create a list structure of tokens.\n",
    "    \n",
    "    doc = sp(text)                             # save spacy document text\n",
    "    \n",
    "    #tokenise\n",
    "    clean = re.sub(r\"(<br />)\",\" \",text)                 #remove any line breaks\n",
    "    clean = re.sub(r\"([@.$&#%~\\*_=\\[\\]/,\\-\\+>;:!?'\\\"”\\)\\(])\",\" \",clean) #remove any punctuation\n",
    "    clean = clean.lower()                                #set all letters to lower case\n",
    "    tokens = re.split(r\"\\s+\",clean)                      #split at white space into tokens\n",
    "    \n",
    "    tokens = removeStop(tokens)                         #remove stopwords\n",
    "    #tokens = spellCorrect(tokens)                       #correct spelling\n",
    "    tokens = stemTokens(tokens)                          #stem tokens\n",
    "    \n",
    "    grams =(list(bigrams(tokens)))                       #Use the nltk bigrams package to return bigrams of filtered text\n",
    "    \n",
    "    return (grams,doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OTHER PRE-PROCESSING METHODS\n",
    "\n",
    "#remove stopwords\n",
    "def removeStop(tokens):\n",
    "    stop_words = set(stopwords.words('english'))       #assign stopwords as the english stopwords list from nltl.corpus\n",
    "    tokens = [w for w in tokens if not w in stop_words]#remove all tokens which are stopwords\n",
    "    return tokens\n",
    "\n",
    "def stemTokens(tokens):\n",
    "    stemmer = PorterStemmer()                          #create stemmer object\n",
    "    for i in range(len(tokens)):                            \n",
    "        tokens[i] = stemmer.stem(tokens[i])            #Use the Porter Stemmer from the nltk package to stem words\n",
    "    return tokens\n",
    "    \n",
    "def spellCorrect(tokens):\n",
    "    tokens_new = []                                    #set up empty array for tokens returned\n",
    "    spell_dict = enchant.Dict('en')                    #create spelling dictionary object using PyEnchant's english dictionary\n",
    "    for t in tokens:                                   #search through the tokens in the review text\n",
    "        if t == \"\":                                    #pass any empty strings that have snuck through\n",
    "            pass                                         \n",
    "        else:                                            \n",
    "            t = replaceToken(t,spell_dict)             #call spellCorrect function to evaluate token\n",
    "            tokens_new = np.append(tokens_new,t)       #append returned value to token array\n",
    "    return tokens_new\n",
    "            \n",
    "def replaceToken(word,d):                              #function to try and correct mispelled words\n",
    "    replace = []                                       #set up empty array for replacement words\n",
    "    if d.check(word) == False:                         #check to see if word is in dictionary, i.e. probably spelled correctly\n",
    "        a = d.suggest(word)                   #If the spelling is incorrect, suggest similar words it could be\n",
    "        for i in range(len(a)):                       \n",
    "            if a[i] and edit_distance(word,a[i]) <= 1: #if one of the similar words can be found with only one letter changed\n",
    "                replace.append(a[i])                   #append this similar word to the empty 'replace' array\n",
    "        if len(replace) == 1:                          #if there is only one word in the replace array\n",
    "            return replace[0]                          #change the token to this word\n",
    "        else:                                       \n",
    "            return word                                #otherwise return original word- therefore this method won't always work\n",
    "    else:                                              # but it also won't change a mispelled word to one with similar letters \n",
    "        return word                                    #but very different meaning hopefully\n",
    "                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction and Vectorisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get text features\n",
    "def getFeatures(tokens,doc):\n",
    "    feature_tokens = []\n",
    "    #ner tokens\n",
    "    ner_tokens = [X.label_ for X in doc.ents]\n",
    "    for t in ner_tokens:\n",
    "        feature_tokens.extend([(t,\"\")])\n",
    "    \n",
    "    #sentiment analysis\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    ss = sid.polarity_scores(doc.text)\n",
    "    sent_dict = {\n",
    "      (\"neg\",\"\"): ss['neg'],\n",
    "      (\"neu\",\"\"): ss['neu'],\n",
    "      (\"pos\",\"\"): ss['pos']\n",
    "    }\n",
    "\n",
    "    # POS tags\n",
    "    tagged_tokens = []\n",
    "    for token in doc:\n",
    "        #tagged_tokens.append(token.dep_)      # Dep tag\n",
    "        tagged_tokens.append(token.pos_)      # UPOS tag\n",
    "        #tagged_tokens.append(token.tag_)      # POS tag\n",
    "\n",
    "    tagged_bigrams =(list(bigrams(tagged_tokens)))\n",
    "    feature_tokens.extend(tagged_bigrams)\n",
    "    \n",
    "    return feature_tokens,sent_dict\n",
    "\n",
    "\n",
    "# function to return only dictionary items with a value over a minimum doc count\n",
    "def min_doc_freq(counts,k):   \n",
    "    count_min = {}\n",
    "    for t in counts:\n",
    "        if counts[t] >= k:\n",
    "            count_min[t] = counts[t]            \n",
    "    #print(\"\\nCounts:\",len(counts))\n",
    "    #print(\"Min:\",len(count_min)) \n",
    "    return count_min\n",
    "    \n",
    "\n",
    "# function to create feature dictionary\n",
    "def toFeatureVector(tokens,Polarity,extra_features=[]):\n",
    "    #seperate tokens and text (text for features)\n",
    "    doc = tokens[1]\n",
    "    tokens = tokens[0]\n",
    "    \n",
    "    counts = Counter(tokens)  # for now a simple count\n",
    "    counts = dict(counts)\n",
    "    p =(bigrams([Polarity,\"\"]))      #create tuple of verified data to enter into dictionary\n",
    "    p = ('polarity',Polarity)\n",
    "    counts[p] = 1                    #this was to avoid equal priority errors when classifying data\n",
    "    \n",
    "    #counts = min_doc_freq(counts,2)\n",
    "    \n",
    "    extra_features,sent_dict = getFeatures(tokens,doc)     # get extra features  \n",
    "    counts.update(sent_dict)                               # add sentiment dictionary\n",
    "    \n",
    "    #add the extra features, for now just adding one count for each extra feature\n",
    "    for feature in extra_features:\n",
    "        if feature in counts:\n",
    "            counts[feature] += 1\n",
    "        else:\n",
    "            counts[feature] = 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureVectorisation(corpus, fitting=False):    \n",
    "    # uses the global variable of the corpus Vectorizer to improve things\n",
    "    if fitting:\n",
    "        corpusVectorizer.fit([toFeatureVector(Text,Polarity) for Text,Polarity,Label in corpus])\n",
    "    doc_feature_matrix = corpusVectorizer.transform([toFeatureVector(Text,Polarity) for Text,Polarity,Label in corpus])\n",
    "    \n",
    "    return doc_feature_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
    "def trainClassifier(trainData):\n",
    "    print(\"Training Classifier...\")\n",
    "    pipeline =  Pipeline([('tfidf', TfidfTransformer()),('chi2', SelectKBest(chi2, k=50000)),('svc', LinearSVC(loss = 'hinge'))])\n",
    "    return SklearnClassifier(pipeline).train(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform cross-validation\n",
    "def crossValidate(data, folds):\n",
    "    shuffle(data)\n",
    "    cv_results = []\n",
    "    foldSize = int(len(data)/folds)\n",
    "    k = 0                                                 # k is used to select the test data from the training data\n",
    "\n",
    "    for x in range(folds):                                # for loop that iterates for each fold\n",
    "        print(\"\\nFold %d: %d - %d\" % (x+1, k, k+foldSize))\n",
    "        testData = data[k:k+foldSize]                     # assign test and train data      \n",
    "        trainData = data[0:k]+data[k+foldSize:]     \n",
    "        y_true = [x[1] for x in testData]                 # find ground truth labels\n",
    "        clf = trainClassifier(trainData)                  # train classifier on training data\n",
    "        y_pred = clf.classify_many(map(lambda t: t[0], testData))\n",
    "        \n",
    "        #evaluate predictions\n",
    "        cv_results.append(metrics.precision_recall_fscore_support(y_true, y_pred, average='weighted'))\n",
    "        k = k+foldSize \n",
    "        \n",
    "    avgResults = [np.mean([x[0] for x in cv_results]),\n",
    "                   np.mean([x[1] for x in cv_results]),\n",
    "                   np.mean([x[2] for x in cv_results])]\n",
    "    \n",
    "    print(\"Cross-Validation Results:\")\n",
    "    print(\"Average Precision: %f\\nAverage Recall: %f\\nAverage F-Score:%f\" % (avgResults[0],avgResults[1],avgResults[2]))\n",
    "    return avgResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
    "\n",
    "def predictLabels(reviewSamples, classifier):\n",
    "    return classifier.classify_many(map(lambda t: t[0], reviewSamples))\n",
    "\n",
    "def predictLabel(reviewSample, classifier):\n",
    "    return classifier.classify(toFeatureVector(preProcess(reviewSample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "   Number of Data Samples: 1600\n",
      "   First Raw Data Sample:\n",
      "\n",
      " (\"While visiting the Chicago area, we chose the Hotel Monaco Chicago for our stay. As one of the premier luxury hotels in Chicago, we held high expectations but were quickly disappointed in what we recieved. The problems began as soon as we arrived. The attendant was not friendly nor did she have the smile that is suppose to be the symbol of Kimpton. And, when we went to our room only to discover that we had not been given what we had paid for, the situation only got worse. Rather than apologize for the error (my credit card receipt was on hand) we were blamed for the indescrpencies in rooms and told that not only was the room we had reserved and paid for more than two months unavailable, we would not recieve a refund of the price difference of the two rooms. I could not believe that a top 40 U.S. hotel that is suppose to be committed to excellence could make such a blunder! With no choice but to retreat back to our room, we were pleasantly pleased with all of the amenities that we did recieve during our stay. A beautiful hotel in the Chicago Loop, but don't go expecting to be treated with respect or professionalism.\\n\", 'negative', 'deceptive')\n",
      "\n",
      "\n",
      "Splitting dataset...\n",
      "   Number of Training Data Samples: 1280 \n",
      "   Number of Test Data Samples: 320\n",
      "\n",
      "\n",
      "Pre-processing dataset...\n",
      "   First Pre-processed Data Sample:\n",
      "\n",
      " (([('visit', 'chicago'), ('chicago', 'area'), ('area', 'chose'), ('chose', 'hotel'), ('hotel', 'monaco'), ('monaco', 'chicago'), ('chicago', 'stay'), ('stay', 'one'), ('one', 'premier'), ('premier', 'luxuri'), ('luxuri', 'hotel'), ('hotel', 'chicago'), ('chicago', 'held'), ('held', 'high'), ('high', 'expect'), ('expect', 'quickli'), ('quickli', 'disappoint'), ('disappoint', 'reciev'), ('reciev', 'problem'), ('problem', 'began'), ('began', 'soon'), ('soon', 'arriv'), ('arriv', 'attend'), ('attend', 'friendli'), ('friendli', 'smile'), ('smile', 'suppos'), ('suppos', 'symbol'), ('symbol', 'kimpton'), ('kimpton', 'went'), ('went', 'room'), ('room', 'discov'), ('discov', 'given'), ('given', 'paid'), ('paid', 'situat'), ('situat', 'got'), ('got', 'wors'), ('wors', 'rather'), ('rather', 'apolog'), ('apolog', 'error'), ('error', 'credit'), ('credit', 'card'), ('card', 'receipt'), ('receipt', 'hand'), ('hand', 'blame'), ('blame', 'indescrp'), ('indescrp', 'room'), ('room', 'told'), ('told', 'room'), ('room', 'reserv'), ('reserv', 'paid'), ('paid', 'two'), ('two', 'month'), ('month', 'unavail'), ('unavail', 'would'), ('would', 'reciev'), ('reciev', 'refund'), ('refund', 'price'), ('price', 'differ'), ('differ', 'two'), ('two', 'room'), ('room', 'could'), ('could', 'believ'), ('believ', 'top'), ('top', '40'), ('40', 'u'), ('u', 'hotel'), ('hotel', 'suppos'), ('suppos', 'commit'), ('commit', 'excel'), ('excel', 'could'), ('could', 'make'), ('make', 'blunder'), ('blunder', 'choic'), ('choic', 'retreat'), ('retreat', 'back'), ('back', 'room'), ('room', 'pleasantli'), ('pleasantli', 'pleas'), ('pleas', 'amen'), ('amen', 'reciev'), ('reciev', 'stay'), ('stay', 'beauti'), ('beauti', 'hotel'), ('hotel', 'chicago'), ('chicago', 'loop'), ('loop', 'go'), ('go', 'expect'), ('expect', 'treat'), ('treat', 'respect'), ('respect', 'profession'), ('profession', '')], While visiting the Chicago area, we chose the Hotel Monaco Chicago for our stay. As one of the premier luxury hotels in Chicago, we held high expectations but were quickly disappointed in what we recieved. The problems began as soon as we arrived. The attendant was not friendly nor did she have the smile that is suppose to be the symbol of Kimpton. And, when we went to our room only to discover that we had not been given what we had paid for, the situation only got worse. Rather than apologize for the error (my credit card receipt was on hand) we were blamed for the indescrpencies in rooms and told that not only was the room we had reserved and paid for more than two months unavailable, we would not recieve a refund of the price difference of the two rooms. I could not believe that a top 40 U.S. hotel that is suppose to be committed to excellence could make such a blunder! With no choice but to retreat back to our room, we were pleasantly pleased with all of the amenities that we did recieve during our stay. A beautiful hotel in the Chicago Loop, but don't go expecting to be treated with respect or professionalism.\n",
      "), 'negative', 'deceptive')\n"
     ]
    }
   ],
   "source": [
    "trainData = []        # the pre-processed training data as a percentage of the total dataset (currently 80%, or 16800 samples)\n",
    "testData = []         # the pre-processed test data as a percentage of the total dataset (currently 20%, or 4200 samples)\n",
    "\n",
    "# The output classes\n",
    "fakeLabel = 'deceptive'\n",
    "realLabel = 'truthful'\n",
    "\n",
    "# References to the data files\n",
    "reviewPath = 'deceptive-opinion.csv'\n",
    "\n",
    "# Parse the dataset and put it in a raw data list\n",
    "print(\"Loading dataset...\")\n",
    "rawData = loadData(reviewPath)\n",
    "shuffle(rawData)\n",
    "print(\"   Number of Data Samples:\",len(rawData))\n",
    "print(\"   First Raw Data Sample:\\n\\n\",rawData[0])\n",
    "\n",
    "# Split the raw dataset into a set of training data and a set of test data (80/20)\n",
    "print(\"\\n\\nSplitting dataset...\")\n",
    "splitData(rawData,0.8)\n",
    "print(\"   Number of Training Data Samples:\",len(trainData),\"\\n   Number of Test Data Samples:\",len(testData))\n",
    "\n",
    "\n",
    "# Pre-process training Data\n",
    "print(\"\\n\\nPre-processing dataset...\")\n",
    "preProcessed_trainData = []\n",
    "for Text,Polarity,Label in trainData:\n",
    "        preProcessed_trainData.append((preProcess(Text),Polarity,Label))\n",
    "print(\"   First Pre-processed Data Sample:\\n\\n\",preProcessed_trainData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Extracting Features from dataset...\n",
      "   First rawData Sample:\n",
      "\n",
      " ({('visit', 'chicago'): 1, ('chicago', 'area'): 1, ('area', 'chose'): 1, ('chose', 'hotel'): 1, ('hotel', 'monaco'): 1, ('monaco', 'chicago'): 1, ('chicago', 'stay'): 1, ('stay', 'one'): 1, ('one', 'premier'): 1, ('premier', 'luxuri'): 1, ('luxuri', 'hotel'): 1, ('hotel', 'chicago'): 2, ('chicago', 'held'): 1, ('held', 'high'): 1, ('high', 'expect'): 1, ('expect', 'quickli'): 1, ('quickli', 'disappoint'): 1, ('disappoint', 'reciev'): 1, ('reciev', 'problem'): 1, ('problem', 'began'): 1, ('began', 'soon'): 1, ('soon', 'arriv'): 1, ('arriv', 'attend'): 1, ('attend', 'friendli'): 1, ('friendli', 'smile'): 1, ('smile', 'suppos'): 1, ('suppos', 'symbol'): 1, ('symbol', 'kimpton'): 1, ('kimpton', 'went'): 1, ('went', 'room'): 1, ('room', 'discov'): 1, ('discov', 'given'): 1, ('given', 'paid'): 1, ('paid', 'situat'): 1, ('situat', 'got'): 1, ('got', 'wors'): 1, ('wors', 'rather'): 1, ('rather', 'apolog'): 1, ('apolog', 'error'): 1, ('error', 'credit'): 1, ('credit', 'card'): 1, ('card', 'receipt'): 1, ('receipt', 'hand'): 1, ('hand', 'blame'): 1, ('blame', 'indescrp'): 1, ('indescrp', 'room'): 1, ('room', 'told'): 1, ('told', 'room'): 1, ('room', 'reserv'): 1, ('reserv', 'paid'): 1, ('paid', 'two'): 1, ('two', 'month'): 1, ('month', 'unavail'): 1, ('unavail', 'would'): 1, ('would', 'reciev'): 1, ('reciev', 'refund'): 1, ('refund', 'price'): 1, ('price', 'differ'): 1, ('differ', 'two'): 1, ('two', 'room'): 1, ('room', 'could'): 1, ('could', 'believ'): 1, ('believ', 'top'): 1, ('top', '40'): 1, ('40', 'u'): 1, ('u', 'hotel'): 1, ('hotel', 'suppos'): 1, ('suppos', 'commit'): 1, ('commit', 'excel'): 1, ('excel', 'could'): 1, ('could', 'make'): 1, ('make', 'blunder'): 1, ('blunder', 'choic'): 1, ('choic', 'retreat'): 1, ('retreat', 'back'): 1, ('back', 'room'): 1, ('room', 'pleasantli'): 1, ('pleasantli', 'pleas'): 1, ('pleas', 'amen'): 1, ('amen', 'reciev'): 1, ('reciev', 'stay'): 1, ('stay', 'beauti'): 1, ('beauti', 'hotel'): 1, ('chicago', 'loop'): 1, ('loop', 'go'): 1, ('go', 'expect'): 1, ('expect', 'treat'): 1, ('treat', 'respect'): 1, ('respect', 'profession'): 1, ('profession', ''): 1, ('polarity', 'negative'): 1, ('neg', ''): 0.099, ('neu', ''): 0.735, ('pos', ''): 0.166, ('GPE', ''): 4, ('ORG', ''): 2, ('CARDINAL', ''): 3, ('DATE', ''): 1, ('SCONJ', 'VERB'): 2, ('VERB', 'DET'): 4, ('DET', 'PROPN'): 3, ('PROPN', 'NOUN'): 2, ('NOUN', 'PUNCT'): 9, ('PUNCT', 'PRON'): 6, ('PRON', 'VERB'): 7, ('PROPN', 'PROPN'): 3, ('PROPN', 'ADP'): 1, ('ADP', 'DET'): 13, ('DET', 'NOUN'): 19, ('PUNCT', 'SCONJ'): 1, ('SCONJ', 'NUM'): 2, ('NUM', 'ADP'): 1, ('NOUN', 'NOUN'): 5, ('NOUN', 'ADP'): 6, ('ADP', 'PROPN'): 2, ('PROPN', 'PUNCT'): 3, ('VERB', 'ADJ'): 2, ('ADJ', 'NOUN'): 2, ('NOUN', 'CCONJ'): 3, ('CCONJ', 'AUX'): 3, ('AUX', 'ADV'): 2, ('ADV', 'ADJ'): 2, ('ADJ', 'ADP'): 2, ('ADP', 'PRON'): 1, ('PRON', 'PRON'): 2, ('VERB', 'PUNCT'): 2, ('PUNCT', 'DET'): 5, ('NOUN', 'VERB'): 2, ('VERB', 'ADV'): 2, ('ADV', 'ADV'): 1, ('ADV', 'SCONJ'): 2, ('SCONJ', 'PRON'): 2, ('NOUN', 'AUX'): 2, ('AUX', 'PART'): 3, ('PART', 'ADJ'): 1, ('ADJ', 'CCONJ'): 1, ('AUX', 'PRON'): 1, ('PRON', 'AUX'): 7, ('AUX', 'DET'): 3, ('NOUN', 'DET'): 3, ('DET', 'AUX'): 2, ('AUX', 'VERB'): 9, ('VERB', 'PART'): 5, ('PART', 'AUX'): 4, ('PUNCT', 'CCONJ'): 2, ('CCONJ', 'PUNCT'): 1, ('PUNCT', 'ADV'): 2, ('ADV', 'PRON'): 1, ('VERB', 'ADP'): 8, ('NOUN', 'ADV'): 2, ('ADV', 'PART'): 1, ('PART', 'VERB'): 5, ('VERB', 'SCONJ'): 3, ('VERB', 'PRON'): 1, ('ADP', 'PUNCT'): 1, ('ADV', 'VERB'): 1, ('ADJ', 'PUNCT'): 2, ('AUX', 'ADP'): 1, ('ADP', 'NOUN'): 4, ('CCONJ', 'VERB'): 2, ('SCONJ', 'PART'): 2, ('PART', 'ADV'): 1, ('ADV', 'AUX'): 1, ('NOUN', 'PRON'): 1, ('VERB', 'CCONJ'): 1, ('ADP', 'ADJ'): 1, ('ADJ', 'SCONJ'): 1, ('NUM', 'NOUN'): 2, ('NOUN', 'ADJ'): 1, ('DET', 'NUM'): 1, ('SCONJ', 'DET'): 1, ('DET', 'ADJ'): 2, ('ADJ', 'NUM'): 1, ('NUM', 'PROPN'): 1, ('VERB', 'VERB'): 2, ('DET', 'DET'): 1, ('PUNCT', 'ADP'): 1, ('NOUN', 'SCONJ'): 1, ('ADV', 'ADP'): 1, ('DET', 'ADP'): 1, ('DET', 'PRON'): 1, ('CCONJ', 'NOUN'): 1, ('PUNCT', 'SPACE'): 1}, 'deceptive')\n"
     ]
    }
   ],
   "source": [
    "# Extract Features training Data\n",
    "print(\"\\n\\nExtracting Features from dataset...\")\n",
    "final_trainData = []\n",
    "for Text,Polarity,Label in preProcessed_trainData:\n",
    "        final_trainData.append(((toFeatureVector(Text,Polarity)),Label))\n",
    "print(\"   First rawData Sample:\\n\\n\",final_trainData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1: 0 - 128\n",
      "Training Classifier...\n",
      "\n",
      "Fold 2: 128 - 256\n",
      "Training Classifier...\n",
      "\n",
      "Fold 3: 256 - 384\n",
      "Training Classifier...\n",
      "\n",
      "Fold 4: 384 - 512\n",
      "Training Classifier...\n",
      "\n",
      "Fold 5: 512 - 640\n",
      "Training Classifier...\n",
      "\n",
      "Fold 6: 640 - 768\n",
      "Training Classifier...\n",
      "\n",
      "Fold 7: 768 - 896\n",
      "Training Classifier...\n",
      "\n",
      "Fold 8: 896 - 1024\n",
      "Training Classifier...\n",
      "\n",
      "Fold 9: 1024 - 1152\n",
      "Training Classifier...\n",
      "\n",
      "Fold 10: 1152 - 1280\n",
      "Training Classifier...\n",
      "Cross-Validation Results:\n",
      "Average Precision: 0.831117\n",
      "Average Recall: 0.826562\n",
      "Average F-Score:0.826409\n"
     ]
    }
   ],
   "source": [
    "# crossValidate function on the training set to get your results\n",
    "cv_results = crossValidate(final_trainData,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   First Test Data Sample:\n",
      "\n",
      " ('The hotel was undergoing renovations so it was dirty and noisy. The entrance was really scary since it was covered with scaffolding, making it dark. They charge a lot for internet hook up, wifi is not included. The staff was very slow, I am assuming they were all new. They could not say where anything was or what attractions were nearby. The room was set up weird, the bathroom opened facing the bed, rather than the hall as most do. Room temp was hard to control, even though they had a digital thermostat. Overall I was very disappointed, had I been staying more than one night I would have switched hotels.\\n', 'negative', 'truthful')\n",
      "\n",
      "\n",
      "Pre-processing dataset...\n",
      "   First Pre-processed Test Data Sample:\n",
      "\n",
      " (([('hotel', 'undergo'), ('undergo', 'renov'), ('renov', 'dirti'), ('dirti', 'noisi'), ('noisi', 'entranc'), ('entranc', 'realli'), ('realli', 'scari'), ('scari', 'sinc'), ('sinc', 'cover'), ('cover', 'scaffold'), ('scaffold', 'make'), ('make', 'dark'), ('dark', 'charg'), ('charg', 'lot'), ('lot', 'internet'), ('internet', 'hook'), ('hook', 'wifi'), ('wifi', 'includ'), ('includ', 'staff'), ('staff', 'slow'), ('slow', 'assum'), ('assum', 'new'), ('new', 'could'), ('could', 'say'), ('say', 'anyth'), ('anyth', 'attract'), ('attract', 'nearbi'), ('nearbi', 'room'), ('room', 'set'), ('set', 'weird'), ('weird', 'bathroom'), ('bathroom', 'open'), ('open', 'face'), ('face', 'bed'), ('bed', 'rather'), ('rather', 'hall'), ('hall', 'room'), ('room', 'temp'), ('temp', 'hard'), ('hard', 'control'), ('control', 'even'), ('even', 'though'), ('though', 'digit'), ('digit', 'thermostat'), ('thermostat', 'overal'), ('overal', 'disappoint'), ('disappoint', 'stay'), ('stay', 'one'), ('one', 'night'), ('night', 'would'), ('would', 'switch'), ('switch', 'hotel'), ('hotel', '')], The hotel was undergoing renovations so it was dirty and noisy. The entrance was really scary since it was covered with scaffolding, making it dark. They charge a lot for internet hook up, wifi is not included. The staff was very slow, I am assuming they were all new. They could not say where anything was or what attractions were nearby. The room was set up weird, the bathroom opened facing the bed, rather than the hall as most do. Room temp was hard to control, even though they had a digital thermostat. Overall I was very disappointed, had I been staying more than one night I would have switched hotels.\n",
      "), 'negative', 'truthful')\n"
     ]
    }
   ],
   "source": [
    "# Finally, check the accuracy of classifier by training on all the training data\n",
    "# and testing on the test set\n",
    "print(\"   First Test Data Sample:\\n\\n\",testData[0])\n",
    "\n",
    "# Pre-process test Data\n",
    "print(\"\\n\\nPre-processing dataset...\")\n",
    "preProcessed_testData = []\n",
    "for Text,Polarity,Label in testData:\n",
    "        preProcessed_testData.append((preProcess(Text),Polarity,Label))\n",
    "print(\"   First Pre-processed Test Data Sample:\\n\\n\",preProcessed_testData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Extracting Features from Test dataset...\n",
      "   First rawData Sample:\n",
      "\n",
      " ({('hotel', 'undergo'): 1, ('undergo', 'renov'): 1, ('renov', 'dirti'): 1, ('dirti', 'noisi'): 1, ('noisi', 'entranc'): 1, ('entranc', 'realli'): 1, ('realli', 'scari'): 1, ('scari', 'sinc'): 1, ('sinc', 'cover'): 1, ('cover', 'scaffold'): 1, ('scaffold', 'make'): 1, ('make', 'dark'): 1, ('dark', 'charg'): 1, ('charg', 'lot'): 1, ('lot', 'internet'): 1, ('internet', 'hook'): 1, ('hook', 'wifi'): 1, ('wifi', 'includ'): 1, ('includ', 'staff'): 1, ('staff', 'slow'): 1, ('slow', 'assum'): 1, ('assum', 'new'): 1, ('new', 'could'): 1, ('could', 'say'): 1, ('say', 'anyth'): 1, ('anyth', 'attract'): 1, ('attract', 'nearbi'): 1, ('nearbi', 'room'): 1, ('room', 'set'): 1, ('set', 'weird'): 1, ('weird', 'bathroom'): 1, ('bathroom', 'open'): 1, ('open', 'face'): 1, ('face', 'bed'): 1, ('bed', 'rather'): 1, ('rather', 'hall'): 1, ('hall', 'room'): 1, ('room', 'temp'): 1, ('temp', 'hard'): 1, ('hard', 'control'): 1, ('control', 'even'): 1, ('even', 'though'): 1, ('though', 'digit'): 1, ('digit', 'thermostat'): 1, ('thermostat', 'overal'): 1, ('overal', 'disappoint'): 1, ('disappoint', 'stay'): 1, ('stay', 'one'): 1, ('one', 'night'): 1, ('night', 'would'): 1, ('would', 'switch'): 1, ('switch', 'hotel'): 1, ('hotel', ''): 1, ('polarity', 'negative'): 1, ('neg', ''): 0.122, ('neu', ''): 0.855, ('pos', ''): 0.023, ('TIME', ''): 1, ('DET', 'NOUN'): 9, ('NOUN', 'AUX'): 6, ('AUX', 'VERB'): 6, ('VERB', 'NOUN'): 2, ('NOUN', 'SCONJ'): 2, ('SCONJ', 'PRON'): 3, ('PRON', 'AUX'): 8, ('AUX', 'ADJ'): 2, ('ADJ', 'CCONJ'): 1, ('CCONJ', 'ADJ'): 1, ('ADJ', 'PUNCT'): 6, ('PUNCT', 'DET'): 4, ('AUX', 'ADV'): 5, ('ADV', 'ADJ'): 4, ('ADJ', 'SCONJ'): 2, ('VERB', 'ADP'): 2, ('ADP', 'NOUN'): 2, ('NOUN', 'PUNCT'): 4, ('PUNCT', 'VERB'): 1, ('VERB', 'PRON'): 2, ('PRON', 'ADJ'): 1, ('PUNCT', 'PRON'): 3, ('PRON', 'VERB'): 3, ('VERB', 'DET'): 2, ('NOUN', 'ADP'): 1, ('NOUN', 'NOUN'): 2, ('NOUN', 'ADV'): 1, ('ADV', 'PUNCT'): 2, ('PUNCT', 'PROPN'): 1, ('PROPN', 'AUX'): 1, ('AUX', 'PART'): 1, ('PART', 'VERB'): 3, ('VERB', 'PUNCT'): 2, ('VERB', 'PART'): 1, ('VERB', 'ADV'): 1, ('ADV', 'PRON'): 2, ('AUX', 'CCONJ'): 1, ('CCONJ', 'DET'): 1, ('ADP', 'ADJ'): 1, ('NOUN', 'VERB'): 1, ('VERB', 'VERB'): 1, ('PUNCT', 'ADV'): 3, ('ADV', 'SCONJ'): 2, ('SCONJ', 'DET'): 1, ('SCONJ', 'ADJ'): 1, ('ADJ', 'AUX'): 1, ('AUX', 'PUNCT'): 1, ('PUNCT', 'NOUN'): 1, ('ADJ', 'PART'): 1, ('AUX', 'DET'): 1, ('DET', 'ADJ'): 1, ('ADJ', 'NOUN'): 1, ('PUNCT', 'AUX'): 1, ('AUX', 'PRON'): 1, ('VERB', 'ADJ'): 1, ('SCONJ', 'NUM'): 1, ('NUM', 'NOUN'): 1, ('NOUN', 'PRON'): 1, ('VERB', 'AUX'): 1, ('PUNCT', 'SPACE'): 1}, 'truthful')\n"
     ]
    }
   ],
   "source": [
    "# Extract Features test Data\n",
    "print(\"\\n\\nExtracting Features from Test dataset...\")\n",
    "final_testData = []\n",
    "for Text,Polarity,Label in preProcessed_testData:\n",
    "        final_testData.append(((toFeatureVector(Text,Polarity)),Label))\n",
    "print(\"   First rawData Sample:\\n\\n\",final_testData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classifier...\n",
      "Done training!\n",
      "\n",
      "Precision: 0.823861\n",
      "Recall: 0.815625\n",
      "F Score:0.814676\n"
     ]
    }
   ],
   "source": [
    "# Train classifer on all train data\n",
    "classifier = trainClassifier(final_trainData)  # train the classifier\n",
    "testTrue = [t[1] for t in final_testData]   # get the ground-truth labels from the data\n",
    "testPred = predictLabels(final_testData, classifier)  # classify the test data to get predicted labels\n",
    "finalScores = metrics.precision_recall_fscore_support(testTrue, testPred, average='weighted') # evaluate\n",
    "print(\"Done training!\")\n",
    "print(\"\\nPrecision: %f\\nRecall: %f\\nF Score:%f\" % finalScores[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
